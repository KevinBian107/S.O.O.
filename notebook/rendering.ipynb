{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Pendulum Control\n",
    "Zero reward is the best condition for the pendulum control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "from mvp.env_pendulum import PendulumEnv\n",
    "\n",
    "from itertools import count\n",
    "import torch\n",
    "import gym\n",
    "from gym.envs.registration import register\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "plt.ion()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pendulum Control Gym\n",
    "\n",
    "## Description\n",
    "The inverted pendulum swingup problem is a classic problem in control theory. The system consists of a pendulum attached at one end to a fixed point, with the other end being free. The pendulum starts in a random position, and the goal is to apply torque to the free end to swing it into an upright position, where its center of gravity is right above the fixed point.\n",
    "\n",
    "### Pendulum Coordinate System\n",
    "\n",
    "- **x-y**: Cartesian coordinates of the pendulum’s end in meters.\n",
    "- **theta**: Angle in radians.\n",
    "- **tau**: Torque in N·m, defined as positive counter-clockwise.\n",
    "\n",
    "### Action Space\n",
    "The action is an ndarray with shape `(1,)` representing the torque applied to the free end of the pendulum.\n",
    "\n",
    "| Num | Action | Min | Max |\n",
    "|-----|--------|-----|-----|\n",
    "| 0   | Torque | -2.0| 2.0 |\n",
    "\n",
    "### Observation Space\n",
    "The observation is an ndarray with shape `(3,)` representing the x-y coordinates of the pendulum’s free end and its angular velocity.\n",
    "\n",
    "| Num | Observation      | Min | Max |\n",
    "|-----|------------------|-----|-----|\n",
    "| 0   | x = cos(theta)   | -1.0| 1.0 |\n",
    "| 1   | y = sin(theta)   | -1.0| 1.0 |\n",
    "| 2   | Angular Velocity | -8.0| 8.0 |\n",
    "\n",
    "### Rewards\n",
    "The reward function is defined as:\n",
    "\n",
    "$r = -(theta^2 + 0.1 * theta_dt^2 + 0.001 * torque^2)$\n",
    "\n",
    "where `theta` is the pendulum’s angle normalized between `[-pi, pi]` (with 0 being in the upright position). The minimum reward that can be obtained is `-(pi^2 + 0.1 * 8^2 + 0.001 * 2^2) = -16.2736044`, while the maximum reward is zero (pendulum is upright with zero velocity and no torque applied)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinb/anaconda3/lib/python3.10/site-packages/gym/envs/registration.py:555: UserWarning: \u001b[33mWARN: The environment Pendulum-v0 is out of date. You should consider upgrading to version `v1`.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "register(\n",
    "    id='Pendulum-v0',\n",
    "    entry_point='mvp.env_pendulum:PendulumEnv',\n",
    "    max_episode_steps=1000)\n",
    "env = gym.make('Pendulum-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(-2.0, 2.0, (1,), float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-inf, inf)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reward_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-1. -1. -8.], [1. 1. 8.], (3,), float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinb/anaconda3/lib/python3.10/site-packages/gym/envs/registration.py:498: UserWarning: \u001b[33mWARN: Overriding environment Pendulum-v1 already in registry.\u001b[0m\n",
      "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.4207256]\n",
      "[2.446133]\n",
      "[2.2714994]\n",
      "[1.8940108]\n",
      "[1.3232177]\n",
      "[0.55958474]\n",
      "[-0.26190308]\n",
      "[-0.9278264]\n",
      "[-1.3315694]\n",
      "[-1.5126436]\n",
      "[-1.548559]\n",
      "[-1.4980936]\n",
      "[-1.4082962]\n",
      "[-1.3291913]\n",
      "[-1.3071458]\n",
      "[-1.3675156]\n",
      "[-1.5068123]\n",
      "[-1.695585]\n",
      "[-1.888982]\n",
      "[-2.0432642]\n",
      "[-2.138118]\n",
      "[-2.1743402]\n",
      "[-2.1471665]\n",
      "[-2.0604918]\n",
      "[-1.9223309]\n",
      "[-1.7528021]\n",
      "[-1.5728025]\n",
      "[-1.3908703]\n",
      "[-1.213364]\n",
      "[-1.0447677]\n",
      "[-0.8880079]\n",
      "[-0.7447523]\n",
      "[-0.61569136]\n",
      "[-0.5007874]\n",
      "[-0.39949605]\n",
      "[-0.31094626]\n",
      "[-0.23408435]\n",
      "[-0.16778274]\n",
      "[-0.11091457]\n",
      "[-0.06240374]\n",
      "[-0.02125367]\n",
      "[0.01343834]\n",
      "[0.04247668]\n",
      "[0.06656948]\n",
      "[0.08633515]\n",
      "[0.1023097]\n",
      "[0.11495648]\n",
      "[0.1246736]\n",
      "[0.13180313]\n",
      "[0.13663837]\n",
      "[0.13943]\n",
      "[0.14039281]\n",
      "[0.13971016]\n",
      "[0.13753851]\n",
      "[0.1340114]\n",
      "[0.12924245]\n",
      "[0.1233283]\n",
      "[0.11635067]\n",
      "[0.10837884]\n",
      "[0.09947072]\n",
      "[0.08967483]\n",
      "[0.07903172]\n",
      "[0.06757395]\n",
      "[0.05532838]\n",
      "[0.04231625]\n",
      "[0.02855388]\n",
      "[0.01405319]\n",
      "[-0.00117754]\n",
      "[-0.01713327]\n",
      "[-0.033812]\n",
      "[-0.05121448]\n",
      "[-0.06934341]\n",
      "[-0.0882039]\n",
      "[-0.10780291]\n",
      "[-0.12814893]\n",
      "[-0.14925222]\n",
      "[-0.1711241]\n",
      "[-0.19377755]\n",
      "[-0.21722633]\n",
      "[-0.24148567]\n",
      "[-0.26657143]\n",
      "[-0.29250097]\n",
      "[-0.31929183]\n",
      "[-0.3469629]\n",
      "[-0.37553406]\n",
      "[-0.40502557]\n",
      "[-0.43545854]\n",
      "[-0.46685544]\n",
      "[-0.49923885]\n",
      "[-0.5326328]\n",
      "[-0.56706166]\n",
      "[-0.60255116]\n",
      "[-0.63912773]\n",
      "[-0.6768186]\n",
      "[-0.7156527]\n",
      "[-0.75565964]\n",
      "[-0.7968699]\n",
      "[-0.8393158]\n",
      "[-0.8830306]\n",
      "[-0.92804945]\n",
      "[-0.97440845]\n",
      "[-1.0221457]\n",
      "[-1.0713007]\n",
      "[-1.1219149]\n",
      "[-1.1740313]\n",
      "[-1.2276944]\n",
      "[-1.2829508]\n",
      "[-1.3398478]\n",
      "[-1.3984343]\n",
      "[-1.4587593]\n",
      "[-1.5208726]\n",
      "[-1.5848215]\n",
      "[-1.6506523]\n",
      "[-1.7184055]\n",
      "[-1.7881147]\n",
      "[-1.859803]\n",
      "[-1.9334769]\n",
      "[-2.0091205]\n",
      "[-2.086744]\n",
      "[-2.1662645]\n",
      "[-2.247646]\n",
      "[-2.329898]\n",
      "[-2.4108021]\n",
      "[-2.4866211]\n",
      "[-2.5518425]\n",
      "[-2.59903]\n",
      "[-2.6188703]\n",
      "[-2.6005342]\n",
      "[-2.5325615]\n",
      "[-2.4046934]\n",
      "[-2.211325]\n",
      "[-1.9566983]\n",
      "[-1.6533589]\n",
      "[-1.3038957]\n",
      "[-0.96473354]\n",
      "[-0.6962876]\n",
      "[-0.5329373]\n",
      "[-0.4666985]\n",
      "[-0.46031266]\n",
      "[-0.474108]\n",
      "[-0.48046473]\n",
      "[-0.46145704]\n",
      "[-0.3995476]\n",
      "[-0.26699424]\n",
      "[-0.01984118]\n",
      "[0.387024]\n",
      "[0.94621944]\n",
      "[1.5523882]\n",
      "[2.0691516]\n",
      "[2.4433403]\n",
      "[2.6960862]\n",
      "[2.800658]\n",
      "[2.7415679]\n",
      "[2.5059743]\n",
      "[2.0852773]\n",
      "[1.4938643]\n",
      "[0.71859926]\n",
      "[-0.12151062]\n",
      "[-0.80810225]\n",
      "[-1.2246435]\n",
      "[-1.4077414]\n",
      "[-1.4347864]\n",
      "[-1.362267]\n",
      "[-1.23617]\n",
      "[-1.1111042]\n",
      "[-1.0396228]\n",
      "[-1.0491323]\n",
      "[-1.135916]\n",
      "[-1.2710985]\n",
      "[-1.4106803]\n",
      "[-1.5102224]\n",
      "[-1.5395344]\n",
      "[-1.4892969]\n",
      "[-1.3676715]\n",
      "[-1.1921219]\n",
      "[-0.982231]\n",
      "[-0.75560874]\n",
      "[-0.52628815]\n",
      "[-0.30447176]\n",
      "[-0.09687226]\n",
      "[0.09272201]\n",
      "[0.2628124]\n",
      "[0.41355914]\n",
      "[0.54621625]\n",
      "[0.6626627]\n",
      "[0.7650504]\n",
      "[0.85556257]\n",
      "[0.93626404]\n",
      "[1.0090238]\n",
      "[1.0754853]\n",
      "[1.1370652]\n",
      "[1.1949701]\n",
      "[1.2502201]\n",
      "[1.3036758]\n",
      "[1.3560624]\n",
      "[1.4079939]\n",
      "[1.4599913]\n",
      "[1.5124999]\n",
      "[1.5659019]\n",
      "[1.6205255]\n",
      "[1.6766534]\n",
      "[1.7345257]\n",
      "[1.7943425]\n",
      "[1.8562598]\n",
      "[1.920386]\n",
      "[1.9867702]\n",
      "[2.0553863]\n",
      "[2.130243]\n",
      "[2.2118886]\n",
      "[2.298859]\n",
      "[2.3880618]\n",
      "[2.4741871]\n",
      "[2.549074]\n",
      "[2.6011086]\n",
      "[2.614716]\n",
      "[2.5699947]\n",
      "[2.4427156]\n",
      "[2.205786]\n",
      "[1.8353487]\n",
      "[1.3011788]\n",
      "[0.59216315]\n",
      "[-0.1660966]\n",
      "[-0.7779907]\n",
      "[-1.14277]\n",
      "[-1.290915]\n",
      "[-1.2838352]\n",
      "[-1.1628916]\n",
      "[-0.9709066]\n",
      "[-0.7752024]\n",
      "[-0.6363547]\n",
      "[-0.5731685]\n",
      "[-0.5682877]\n",
      "[-0.583623]\n",
      "[-0.57340014]\n",
      "[-0.4990018]\n",
      "[-0.34142426]\n",
      "[-0.10494681]\n",
      "[0.18893193]\n",
      "[0.5117632]\n",
      "[0.836142]\n",
      "[1.1393528]\n",
      "[1.4037075]\n",
      "[1.6148621]\n",
      "[1.7589142]\n",
      "[1.8188312]\n",
      "[1.770843]\n",
      "[1.5826285]\n",
      "[1.2196122]\n",
      "[0.67349666]\n",
      "[0.01583601]\n",
      "[-0.5916215]\n",
      "[-1.0080974]\n",
      "[-1.2111468]\n",
      "[-1.2444218]\n",
      "[-1.144352]\n",
      "[-0.9641547]\n",
      "[-0.73356384]\n",
      "[-0.5440331]\n",
      "[-0.42946798]\n",
      "[-0.37794536]\n",
      "[-0.35328162]\n",
      "[-0.3104217]\n",
      "[-0.2109493]\n",
      "[-0.03767063]\n",
      "[0.19937068]\n",
      "[0.4681359]\n",
      "[0.7257011]\n",
      "[0.9271001]\n",
      "[1.0288333]\n",
      "[0.98956084]\n",
      "[0.7750212]\n",
      "[0.37897804]\n",
      "[-0.13798222]\n",
      "[-0.6398202]\n",
      "[-0.99719167]\n",
      "[-1.1723273]\n",
      "[-1.1978972]\n",
      "[-1.144624]\n",
      "[-0.9813574]\n",
      "[-0.7503499]\n",
      "[-0.5554537]\n",
      "[-0.4348173]\n",
      "[-0.37926143]\n",
      "[-0.35387433]\n",
      "[-0.3137746]\n",
      "[-0.21947812]\n",
      "[-0.05184357]\n",
      "[0.18104438]\n",
      "[0.44834885]\n",
      "[0.70746195]\n",
      "[0.91322714]\n",
      "[1.0218388]\n",
      "[0.9916399]\n",
      "[0.7875943]\n",
      "[0.40110517]\n",
      "[-0.11158387]\n",
      "[-0.6172151]\n",
      "[-0.98335063]\n",
      "[-1.1672664]\n",
      "[-1.1977967]\n",
      "[-1.1499563]\n",
      "[-0.9921117]\n",
      "[-0.76105756]\n",
      "[-0.5627914]\n",
      "[-0.43818036]\n",
      "[-0.37987423]\n",
      "[-0.35381475]\n",
      "[-0.31528044]\n",
      "[-0.22416313]\n",
      "[-0.0601186]\n",
      "[0.17000589]\n",
      "[0.43613958]\n",
      "[0.69586444]\n",
      "[0.9038669]\n",
      "[1.016099]\n",
      "[0.9906751]\n",
      "[0.79215515]\n",
      "[0.41080928]\n",
      "[-0.09925066]\n",
      "[-0.6062706]\n",
      "[-0.9764428]\n",
      "[-1.1645612]\n",
      "[-1.1976535]\n",
      "[-1.1524744]\n",
      "[-0.99731565]\n",
      "[-0.7663029]\n",
      "[-0.56640327]\n",
      "[-0.43981728]\n",
      "[-0.38011402]\n",
      "[-0.35366473]\n",
      "[-0.3158416]\n",
      "[-0.22624484]\n",
      "[-0.06395365]\n",
      "[0.16478692]\n",
      "[0.43028265]\n",
      "[0.6902043]\n",
      "[0.89915204]\n",
      "[1.0129454]\n",
      "[0.9895782]\n",
      "[0.7934338]\n",
      "[0.41432643]\n",
      "[-0.09449844]\n",
      "[-0.601929]\n",
      "[-0.9736414]\n",
      "[-1.163414]\n",
      "[-1.1975781]\n",
      "[-1.153477]\n",
      "[-0.9994118]\n",
      "[-0.76842797]\n",
      "[-0.56787014]\n",
      "[-0.44047865]\n",
      "[-0.3802002]\n",
      "[-0.35358208]\n",
      "[-0.316036]\n",
      "[-0.22704886]\n",
      "[-0.06546696]\n",
      "[0.16270788]\n",
      "[0.42793345]\n",
      "[0.6879163]\n",
      "[0.8972191]\n",
      "[1.0116057]\n",
      "[0.98901916]\n",
      "[0.7937757]\n",
      "[0.41552204]\n",
      "[-0.09281458]\n",
      "[-0.6003632]\n",
      "[-0.9726181]\n",
      "[-1.162985]\n",
      "[-1.1975479]\n",
      "[-1.1538415]\n",
      "[-1.0001779]\n",
      "[-0.76920664]\n",
      "[-0.56840783]\n",
      "[-0.44072092]\n",
      "[-0.38023013]\n",
      "[-0.35354862]\n",
      "[-0.3161025]\n",
      "[-0.2273377]\n",
      "[-0.06601523]\n",
      "[0.16195153]\n",
      "[0.42707643]\n",
      "[0.6870787]\n",
      "[0.89650786]\n",
      "[1.0111063]\n",
      "[0.98879826]\n",
      "[0.79387593]\n",
      "[0.41592735]\n",
      "[-0.09223218]\n",
      "[-0.5998175]\n",
      "[-0.9722594]\n",
      "[-1.162833]\n",
      "[-1.197537]\n",
      "[-1.1539692]\n",
      "[-1.0004468]\n",
      "[-0.76948]\n",
      "[-0.5685969]\n",
      "[-0.44080585]\n",
      "[-0.38024056]\n",
      "[-0.3535362]\n",
      "[-0.31612554]\n",
      "[-0.22743829]\n",
      "[-0.06620722]\n",
      "[0.16168658]\n",
      "[0.42677587]\n",
      "[0.6867847]\n",
      "[0.8962576]\n",
      "[1.0109295]\n",
      "[0.9887183]\n",
      "[0.7939074]\n",
      "[0.41606468]\n",
      "[-0.09203275]\n",
      "[-0.5996298]\n",
      "[-0.9721358]\n",
      "[-1.1627806]\n",
      "[-1.1975331]\n",
      "[-1.1540133]\n",
      "[-1.0005395]\n",
      "[-0.76957434]\n",
      "[-0.568662]\n",
      "[-0.44083515]\n",
      "[-0.3802439]\n",
      "[-0.35353208]\n",
      "[-0.3161332]\n",
      "[-0.22747305]\n",
      "[-0.06627329]\n",
      "[0.16159512]\n",
      "[0.4266721]\n",
      "[0.68668324]\n",
      "[0.8961712]\n",
      "[1.0108685]\n",
      "[0.98869073]\n",
      "[0.79391825]\n",
      "[0.41611192]\n",
      "[-0.09196411]\n",
      "[-0.59956515]\n",
      "[-0.9720932]\n",
      "[-1.1627622]\n",
      "[-1.1975319]\n",
      "[-1.1540283]\n",
      "[-1.0005715]\n",
      "[-0.76960695]\n",
      "[-0.5686847]\n",
      "[-0.44084525]\n",
      "[-0.3802451]\n",
      "[-0.35353053]\n",
      "[-0.31613588]\n",
      "[-0.22748478]\n",
      "[-0.06629591]\n",
      "[0.1615638]\n",
      "[0.42663658]\n",
      "[0.68664837]\n",
      "[0.8961415]\n",
      "[1.0108474]\n",
      "[0.9886809]\n",
      "[0.7939217]\n",
      "[0.41612792]\n",
      "[-0.09194075]\n",
      "[-0.5995432]\n",
      "[-0.9720787]\n",
      "[-1.162756]\n",
      "[-1.1975313]\n",
      "[-1.1540335]\n",
      "[-1.0005823]\n",
      "[-0.76961786]\n",
      "[-0.5686923]\n",
      "[-0.44084883]\n",
      "[-0.3802455]\n",
      "[-0.3535301]\n",
      "[-0.31613687]\n",
      "[-0.22748896]\n",
      "[-0.06630377]\n",
      "[0.16155313]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(state, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32, device\u001b[38;5;241m=\u001b[39mdevice)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m count():\n\u001b[0;32m---> 20\u001b[0m     \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# Get action from the model (assuming it outputs action_mean, action_std, and value)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m~/Desktop/CL/Simple_CL_Env/mvp/env_pendulum.py:254\u001b[0m, in \u001b[0;36mPendulumEnv.render\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    253\u001b[0m     pygame\u001b[38;5;241m.\u001b[39mevent\u001b[38;5;241m.\u001b[39mpump()\n\u001b[0;32m--> 254\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrender_fps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m     pygame\u001b[38;5;241m.\u001b[39mdisplay\u001b[38;5;241m.\u001b[39mflip()\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# mode == \"rgb_array\":\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from mvp.ppo_continuous import ActorCritic\n",
    "\n",
    "path = os.path.join(os.getcwd(), \"..\", \"mvp\", \"params\", \"pendulum_ppo_continuous.pth\")\n",
    "\n",
    "env = PendulumEnv(render_mode=\"human\")\n",
    "n_actions = env.action_space.shape[0]\n",
    "state, info = env.reset()\n",
    "n_observations = len(state)\n",
    "num_eval_episodes = 10\n",
    "\n",
    "model = ActorCritic(n_observations, n_actions).to(device)\n",
    "model.load_state_dict(torch.load(path, map_location=device))\n",
    "model.eval()\n",
    "\n",
    "for i_episode in range(num_eval_episodes):\n",
    "    state, info = env.reset()\n",
    "    state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "    for t in count():\n",
    "        env.render()\n",
    "        # Get action from the model (assuming it outputs action_mean, action_std, and value)\n",
    "        with torch.no_grad():\n",
    "            action_mean, _, _ = model(state)\n",
    "        \n",
    "        # Take the mean action (no sampling here for deterministic behavior)\n",
    "        action = action_mean.cpu().numpy()[0]\n",
    "        print(action)\n",
    "\n",
    "        observation, reward, terminated, truncated, _ = env.step(action)\n",
    "        if terminated or truncated:\n",
    "            print(f\"Episode finished after {t+1} timesteps\")\n",
    "            break\n",
    "\n",
    "        state = torch.tensor(observation, dtype=torch.float32, device=device).unsqueeze(0)\n",
    "        \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
