# Sub-Optimality Optimization (S.O.O.)
I am currently researching into the theoretical aspects of Continual Learning with advising from professor Sicun Gao in UCSD CSE. I try to frame the general problem of Continual Learning from the perspective of Reinforcement Learning & Cognitive Neuroscience, hoping to develop algorithms that utilize the same strategies of "how we learn" onto an artificial agent.

We need to focus on the core problem in this project: how to construct a good q-distribution that captures overall environmental dynamics (1. how do we get enough sampling at each subtask? 2. How can we gradually learn this cohesive picture, not focusing on the forgetting part, rather focus on building a holistic picture) while developing task specific policy that works well enough given current environmental status  (1. how can we build such general controller?)

Visit documentation page: https://kbian.org/S.O.O./
